import logging
import os
import torch
import numpy as np
import chromadb
import asyncio
from fastapi import FastAPI, HTTPException, BackgroundTasks, Request
from pydantic import BaseModel, Field
from typing import List
from sentence_transformers import SentenceTransformer, util
import gdown
from pathlib import Path

# --- 1. Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ùˆ Ø«Ø§Ø¨Øªâ€ŒÙ‡Ø§ ---
BASE_DATA_DIR = Path("/app/product_db")
DB_PATH = str(BASE_DATA_DIR)
MODEL_PATH = str(BASE_DATA_DIR / "embedding_model")
COLLECTION_NAME = "products"
API_VERSION = "1.2.0-async"
TOP_K_RESULTS = 15

# --- 2. Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù„Ø§Ú¯ ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- 3. Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ Ùˆ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ---
model: SentenceTransformer = None
collection = None
app_initialized = False

# --- 4. Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Pydantic ---
class HybridSearchRequest(BaseModel):
    query: str = Field(..., description="The full-text query for semantic search.", example="velvet kitchen rug")
    keywords: List[str] = Field(..., description="A list of keywords for initial filtering.", example=["rug", "velvet"])

class SearchResult(BaseModel):
    id: str = Field(..., description="Unique identifier of the product.")
    name: str = Field(..., description="The Persian name of the product.")
    score: float = Field(..., description="The semantic similarity score as a percentage (0-100).")

class DownloadRequest(BaseModel):
    drive_link: str = Field(..., description="Ù„ÛŒÙ†Ú© Ø§Ø´ØªØ±Ø§Ú©â€ŒÚ¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ø¯Ø± Ú¯ÙˆÚ¯Ù„ Ø¯Ø±Ø§ÛŒÙˆ")
    destination_path: str = Field("", description="Ù…Ø³ÛŒØ± Ù†Ø³Ø¨ÛŒ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ø±ÙˆÛŒ Ø¯ÛŒØ³Ú© (Ù…Ø«Ø§Ù„: embedding_model)")

# --- 5. Ø³Ø§Ø®Øª Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† FastAPI ---
app = FastAPI(
    title="Async Unified Hybrid Search and Downloader API",
    description="An asynchronous API that downloads files, initializes a search model, and performs hybrid search.",
    version=API_VERSION
)

# --- 6. ØªÙˆØ§Ø¨Ø¹ Ù‡Ù…Ø²Ù…Ø§Ù† (Sync) Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ Ø¯Ø± Thread Pool ---
def initialize_components_sync():
    """
    Ù†Ø³Ø®Ù‡ Ù‡Ù…Ø²Ù…Ø§Ù† (sync) ØªØ§Ø¨Ø¹ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ú©Ù‡ Ø´Ø§Ù…Ù„ Ú©Ø¯Ù‡Ø§ÛŒ blocking Ø§Ø³Øª.
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¯Ø± ÛŒÚ© thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø§Ø¬Ø±Ø§ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.
    """
    global model, collection, app_initialized
    if not os.path.exists(MODEL_PATH) or not os.path.isdir(DB_PATH):
        raise FileNotFoundError("Model or Database path does not exist. Please download files first.")
    
    logger.info("--- Ø¯Ø± Ø­Ø§Ù„ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§Ø² Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­Ù„ÛŒ ---")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    logger.info(f"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø§Ø² Ù…Ø³ÛŒØ±: {MODEL_PATH} Ø±ÙˆÛŒ Ø¯Ø³ØªÚ¯Ø§Ù‡: '{device}'")
    model = SentenceTransformer(MODEL_PATH, device=device)
    logger.info("âœ… Ù…Ø¯Ù„ Ø§Ù…Ø¨Ø¯ÛŒÙ†Ú¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")

    logger.info(f"Ø¯Ø± Ø­Ø§Ù„ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ChromaDB Ø¯Ø± Ù…Ø³ÛŒØ±: {DB_PATH}")
    db_client = chromadb.PersistentClient(path=DB_PATH)
    collection = db_client.get_or_create_collection(name=COLLECTION_NAME)
    logger.info(f"âœ… Ø§ØªØµØ§Ù„ Ø¨Ù‡ ChromaDB Ù…ÙˆÙÙ‚ÛŒØªâ€ŒØ¢Ù…ÛŒØ² Ø¨ÙˆØ¯. Ú©Ø§Ù„Ú©Ø´Ù† '{COLLECTION_NAME}' Ø´Ø§Ù…Ù„ {collection.count()} Ø¢ÛŒØªÙ… Ø§Ø³Øª.")
    
    app_initialized = True

def search_sync(query: str, keywords: List[str]) -> List[SearchResult]:
    """
    Ù†Ø³Ø®Ù‡ Ù‡Ù…Ø²Ù…Ø§Ù† (sync) ØªØ§Ø¨Ø¹ Ø¬Ø³ØªØ¬Ùˆ. ØªÙ…Ø§Ù… Ú©Ø¯Ù‡Ø§ÛŒ Ø³Ù†Ú¯ÛŒÙ† CPU-bound Ø§ÛŒÙ†Ø¬Ø§ Ù‡Ø³ØªÙ†Ø¯.
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¯Ø± ÛŒÚ© thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø§Ø¬Ø±Ø§ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.
    """
    # ÙÛŒÙ„ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡
    where_filter = {"$or": [{"$contains": kw} for kw in keywords]} if len(keywords) > 1 else {"$contains": keywords[0]}
    results_keyword = collection.get(where_document=where_filter, include=["documents", "embeddings"])
    
    if not results_keyword or not results_keyword.get('ids'):
        logger.info("Ù¾Ø³ Ø§Ø² ÙÛŒÙ„ØªØ± Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return []

    logger.info(f"ØªØ¹Ø¯Ø§Ø¯ {len(results_keyword['ids'])} Ù†ØªÛŒØ¬Ù‡ Ù¾Ø³ Ø§Ø² ÙÛŒÙ„ØªØ± Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ ÛŒØ§ÙØª Ø´Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¬Ø¯Ø¯...")

    # Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¬Ø¯Ø¯ Ø¨Ø§ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ (Ø¨Ø®Ø´ Ø³Ù†Ú¯ÛŒÙ†)
    full_query_embedding = model.encode(query)
    filtered_embeddings = np.array(results_keyword['embeddings'], dtype=np.float32)
    similarities = util.cos_sim(full_query_embedding, filtered_embeddings)

    reranked_results = [
        {
            "id": results_keyword['ids'][i],
            "name": doc_name,
            "score": similarities[0][i].item() * 100
        }
        for i, doc_name in enumerate(results_keyword['documents'])
    ]
    
    reranked_results.sort(key=lambda x: x['score'], reverse=True)
    return reranked_results[:TOP_K_RESULTS]

def start_download(url: str, output_path: Path):
    """ØªØ§Ø¨Ø¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù‡ Ø¯Ø± Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯ (Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ async Ù†Ø¯Ø§Ø±Ø¯)."""
    # ... (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
    logger.info(f"ğŸš€ Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø² {url} Ø¨Ù‡ {output_path}")
    try:
        output_path.parent.mkdir(parents=True, exist_ok=True)
        gdown.download(url=url, output=str(output_path), quiet=False, fuzzy=True)
        logger.info(f"âœ… Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø±Ø§ÛŒ {output_path} Ú©Ø§Ù…Ù„ Ø´Ø¯.")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ {url}. Ø¯Ù„ÛŒÙ„: {e}")

# --- 7. Endpoint Ù‡Ø§ÛŒ API (Asynchronous) ---
@app.post("/startup/")
async def startup_server():
    """
    Endpoint ØºÛŒØ±Ù‡Ù…Ø²Ù…Ø§Ù† (async) Ø¨Ø±Ø§ÛŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø¯Ù„ Ùˆ Ø¯ÛŒØªØ§Ø¨ÛŒØ³.
    """
    global app_initialized
    if app_initialized:
        return {"status": "warning", "message": "Application is already initialized."}
    
    try:
        # Ø§Ø¬Ø±Ø§ÛŒ ØªØ§Ø¨Ø¹ blocking Ø¯Ø± ÛŒÚ© thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
        await asyncio.get_running_loop().run_in_executor(None, initialize_components_sync)
        return {"status": "success", "message": "Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯Ù†Ø¯."}
    except Exception as e:
        # Ø±ÛŒØ³Øª Ú©Ø±Ø¯Ù† ÙˆØ¶Ø¹ÛŒØª Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ø®Ø·Ø§
        app_initialized = False
        logger.critical(f"âŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯: {str(e)}")

@app.post("/get-files/")
async def schedule_download(request: DownloadRequest, background_tasks: BackgroundTasks):
    """Endpoint Ø¨Ø±Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ (Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ async Ø¨Ø§Ø´Ø¯ ÙˆÙ„ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ù†ÛŒØ³Øª)."""
    # ... (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
    full_path = BASE_DATA_DIR.joinpath(request.destination_path).resolve()
    if BASE_DATA_DIR not in full_path.parents and full_path != BASE_DATA_DIR:
        raise HTTPException(
            status_code=400,
            detail="Ø®Ø·Ø§: Ù…Ø³ÛŒØ± Ù…Ù‚ØµØ¯ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª."
        )
    background_tasks.add_task(start_download, request.drive_link, full_path)
    return {
        "status": "success",
        "message": "ÙˆØ¸ÛŒÙÙ‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯.",
        "details": {
            "drive_link": request.drive_link,
            "save_location": str(full_path)
        }
    }

@app.post("/hybrid-search/", response_model=List[SearchResult])
async def hybrid_search(request: HybridSearchRequest):
    """
    âœ¨ Endpoint Ø§ØµÙ„ÛŒ Ø¬Ø³ØªØ¬Ùˆ Ú©Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª ØºÛŒØ±Ù‡Ù…Ø²Ù…Ø§Ù† (async) Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯. âœ¨
    """
    if not app_initialized or collection is None or model is None:
        raise HTTPException(status_code=503, detail="Ø³Ø±ÙˆÛŒØ³ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ Ø§Ø¨ØªØ¯Ø§ /startup Ø±Ø§ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ú©Ù†ÛŒØ¯.")

    if not request.keywords:
        raise HTTPException(status_code=400, detail="Ù„ÛŒØ³Øª Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯.")

    try:
        # Ø§Ø¬Ø±Ø§ÛŒ ØªØ§Ø¨Ø¹ Ø³Ù†Ú¯ÛŒÙ† Ùˆ Ù‡Ù…Ø²Ù…Ø§Ù†Ù Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± ÛŒÚ© thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
        # Ø§ÛŒÙ† Ú©Ø§Ø± Ø§Ø² Ù…Ø³Ø¯ÙˆØ¯ Ø´Ø¯Ù† event loop Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
        loop = asyncio.get_running_loop()
        final_results = await loop.run_in_executor(
            None,  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² thread pool Ù¾ÛŒØ´â€ŒÙØ±Ø¶
            search_sync,  # ØªØ§Ø¨Ø¹ Ù‡Ù…Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯
            request.query,  # Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†â€ŒÙ‡Ø§ÛŒ ØªØ§Ø¨Ø¹
            request.keywords
        )
        logger.info(f"Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† {len(final_results)} Ù†ØªÛŒØ¬Ù‡ Ù†Ù‡Ø§ÛŒÛŒ.")
        return final_results
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø­ÛŒÙ† Ø¬Ø³ØªØ¬Ùˆ: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ø­ÛŒÙ† ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¬Ø³ØªØ¬Ùˆ Ø±Ø® Ø¯Ø§Ø¯.")

@app.get("/", summary="Health Check")
async def read_root():
    """Endpoint Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª Ø³Ø±ÙˆÛŒØ³."""
    return {
        "status": "OK" if app_initialized else "Pending Initialization",
        "message": "Server is running. Call /startup to initialize model and DB.",
        "version": API_VERSION,
        "initialized": app_initialized
    }

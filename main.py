import logging
import os
import chromadb
import asyncio
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel, Field
from typing import List
from pathlib import Path
import gdown

# --- 1. Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ùˆ Ø«Ø§Ø¨Øªâ€ŒÙ‡Ø§ ---
BASE_DATA_DIR = Path("/app/product_db")
DB_PATH = str(BASE_DATA_DIR)
COLLECTION_NAME = "products"
API_VERSION = "2.0.0-headless"
TOP_K_RESULTS = 15

# --- 2. Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù„Ø§Ú¯ ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- 3. Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ ---
collection = None
app_initialized = False

# --- 4. Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Pydantic ---
class VectorSearchRequest(BaseModel):
    embedding: List[float] = Field(..., description="The pre-computed embedding vector for the query.")
    keywords: List[str] = Field(..., description="A list of keywords for initial filtering.", example=["rug", "velvet"])

class SearchResult(BaseModel):
    id: str
    name: str
    score: float

class DownloadRequest(BaseModel):
    drive_link: str
    destination_path: str = ""

# --- 5. Ø³Ø§Ø®Øª Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† FastAPI ---
app = FastAPI(
    title="Headless Vector Search API",
    description="An API that receives pre-computed embeddings and performs a hybrid search in ChromaDB.",
    version=API_VERSION
)

# --- 6. ØªÙˆØ§Ø¨Ø¹ Ù‡Ù…Ø²Ù…Ø§Ù† (Sync) ---
def initialize_database_sync():
    """ÙÙ‚Ø· Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    global collection, app_initialized
    if not os.path.isdir(DB_PATH):
        raise FileNotFoundError("Database path does not exist. Please download the database first.")
    
    logger.info(f"--- Ø¯Ø± Ø­Ø§Ù„ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ChromaDB Ø¯Ø± Ù…Ø³ÛŒØ±: {DB_PATH} ---")
    db_client = chromadb.PersistentClient(path=DB_PATH)
    collection = db_client.get_or_create_collection(name=COLLECTION_NAME)
    logger.info(f"âœ… Ø§ØªØµØ§Ù„ Ø¨Ù‡ ChromaDB Ù…ÙˆÙÙ‚ÛŒØªâ€ŒØ¢Ù…ÛŒØ² Ø¨ÙˆØ¯. Ú©Ø§Ù„Ú©Ø´Ù† '{COLLECTION_NAME}' Ø´Ø§Ù…Ù„ {collection.count()} Ø¢ÛŒØªÙ… Ø§Ø³Øª.")
    app_initialized = True

def search_sync(embedding: List[float], keywords: List[str]) -> List[SearchResult]:
    """Ø¬Ø³ØªØ¬ÙˆÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙˆÚ©ØªÙˆØ± Ø¢Ù…Ø§Ø¯Ù‡."""
    # Ù…Ø±Ø­Ù„Ù‡ Û±: ÙÛŒÙ„ØªØ± Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø§ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡
    where_filter = {"$or": [{"$contains": kw} for kw in keywords]} if len(keywords) > 1 else {"$contains": keywords[0]}
    
    # Ø¯Ø± Ø§ÛŒÙ† Ù…Ø±Ø­Ù„Ù‡ ÙÙ‚Ø· Ø§Ø³Ù†Ø§Ø¯ (documents) Ùˆ Ø´Ù†Ø§Ø³Ù‡â€ŒÙ‡Ø§ (ids) Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…ØŒ Ú†ÙˆÙ† Ø¨Ù‡ Ø§Ù…Ø¨Ø¯ÛŒÙ†Ú¯â€ŒÙ‡Ø§ÛŒØ´Ø§Ù† Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†ÛŒØ§Ø²ÛŒ Ù†Ø¯Ø§Ø±ÛŒÙ…
    results_keyword = collection.get(where_document=where_filter, include=["documents"])
    
    if not results_keyword or not results_keyword.get('ids'):
        return []
        
    # Ù…Ø±Ø­Ù„Ù‡ Û²: Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø±ÙˆÛŒ Ù†ØªØ§ÛŒØ¬ ÙÛŒÙ„ØªØ± Ø´Ø¯Ù‡
    # ChromaDB Ø¨Ù‡ ØµÙˆØ±Øª Ø¯Ø§Ø®Ù„ÛŒ Ø´Ø¨Ø§Ù‡Øª Ú©Ø³ÛŒÙ†ÙˆØ³ÛŒ Ø±Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    vector_search_results = collection.query(
        query_embeddings=[embedding],
        n_results=TOP_K_RESULTS,
        where={"id": {"$in": results_keyword['ids']}} # Ø¬Ø³ØªØ¬Ùˆ ÙÙ‚Ø· Ø±ÙˆÛŒ Ø§Ø³Ù†Ø§Ø¯ÛŒ Ú©Ù‡ Ø§Ø² ÙÛŒÙ„ØªØ± Ø±Ø¯ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯
    )

    if not vector_search_results or not vector_search_results.get('ids')[0]:
        return []

    # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
    final_results = []
    ids = vector_search_results['ids'][0]
    distances = vector_search_results['distances'][0]
    documents = vector_search_results['documents'][0]

    for i in range(len(ids)):
        # ØªØ¨Ø¯ÛŒÙ„ ÙØ§ØµÙ„Ù‡ (distance) Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø´Ø¨Ø§Ù‡Øª (similarity score)
        score = (1 - distances[i]) * 100
        final_results.append({
            "id": ids[i],
            "name": documents[i],
            "score": score
        })
        
    return final_results

def start_download(url: str, output_path: Path):
    """ØªØ§Ø¨Ø¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù‡ Ø¯Ø± Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯."""
    logger.info(f"ğŸš€ Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø² {url} Ø¨Ù‡ {output_path}")
    try:
        output_path.parent.mkdir(parents=True, exist_ok=True)
        gdown.download(url=url, output=str(output_path), quiet=False, fuzzy=True)
        logger.info(f"âœ… Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø±Ø§ÛŒ {output_path} Ú©Ø§Ù…Ù„ Ø´Ø¯.")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ {url}. Ø¯Ù„ÛŒÙ„: {e}")

# --- 7. Endpoint Ù‡Ø§ÛŒ API (Asynchronous) ---
@app.post("/startup/")
async def startup_server():
    """Endpoint Ø¨Ø±Ø§ÛŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³."""
    global app_initialized
    if app_initialized:
        return {"status": "warning", "message": "Application is already initialized."}
    try:
        await asyncio.get_running_loop().run_in_executor(None, initialize_database_sync)
        return {"status": "success", "message": "Database initialized successfully."}
    except Exception as e:
        app_initialized = False
        logger.critical(f"âŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Failed to initialize database: {str(e)}")

@app.post("/get-files/")
async def schedule_download(request: DownloadRequest, background_tasks: BackgroundTasks):
    """Endpoint Ø¨Ø±Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ (Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ async Ø¨Ø§Ø´Ø¯ ÙˆÙ„ÛŒ Ø¶Ø±ÙˆØ±ÛŒ Ù†ÛŒØ³Øª)."""
    # ... (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
    full_path = BASE_DATA_DIR.joinpath(request.destination_path).resolve()
    if BASE_DATA_DIR not in full_path.parents and full_path != BASE_DATA_DIR:
        raise HTTPException(
            status_code=400,
            detail="Ø®Ø·Ø§: Ù…Ø³ÛŒØ± Ù…Ù‚ØµØ¯ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª."
        )
    background_tasks.add_task(start_download, request.drive_link, full_path)
    return {
        "status": "success",
        "message": "ÙˆØ¸ÛŒÙÙ‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯.",
        "details": {
            "drive_link": request.drive_link,
            "save_location": str(full_path)
        }
    }

@app.post("/vector-search/", response_model=List[SearchResult])
async def vector_search(request: VectorSearchRequest):
    """Endpoint Ø§ØµÙ„ÛŒ Ø¬Ø³ØªØ¬Ùˆ Ú©Ù‡ ÙˆÚ©ØªÙˆØ± Ø¢Ù…Ø§Ø¯Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    if not app_initialized:
        raise HTTPException(status_code=503, detail="Service is not initialized. Please call /startup first.")
    if not request.keywords:
        raise HTTPException(status_code=400, detail="Keywords list cannot be empty.")
    try:
        loop = asyncio.get_running_loop()
        final_results = await loop.run_in_executor(None, search_sync, request.embedding, request.keywords)
        logger.info(f"Returning {len(final_results)} search results.")
        return final_results
    except Exception as e:
        logger.error(f"Error during search: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="An error occurred during the search process.")

@app.get("/", summary="Health Check")
async def read_root():
    """Endpoint Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª Ø³Ø±ÙˆÛŒØ³."""
    return {
        "status": "OK" if app_initialized else "Pending Initialization",
        "message": "Server is running. Call /startup to initialize model and DB.",
        "version": API_VERSION,
        "initialized": app_initialized
    }

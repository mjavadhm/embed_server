import logging
import os
import chromadb
import asyncio
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel, Field
from typing import List, Optional
from pathlib import Path
import gdown

# --- 1. Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ùˆ Ø«Ø§Ø¨Øªâ€ŒÙ‡Ø§ ---
BASE_DATA_DIR = Path("/app/product_db")
DB_PATH = str(BASE_DATA_DIR)
COLLECTION_NAME = "products"
API_VERSION = "2.4.0-final-debug" # Version updated to reflect changes
TOP_K_RESULTS = 15

# --- 2. Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù„Ø§Ú¯ ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- 3. Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ ---
collection = None
app_initialized = False

# --- 4. Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Pydantic ---
class VectorSearchRequest(BaseModel):
    embedding: List[float] = Field(..., description="The pre-computed embedding vector for the query.")
    keywords: List[str] = Field(..., description="A list of keywords for initial filtering.", example=["rug", "velvet"])

class SearchResult(BaseModel):
    id: str
    name: str
    score: float

class DownloadRequest(BaseModel):
    drive_link: str = Field(..., description="Google Drive link for the folder to download.")
    # ### ØªØºÛŒÛŒØ±: destination_path Ø­Ø°Ù Ø´Ø¯ Ú†ÙˆÙ† gdown.download_folder Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¯Ø± Ù…Ø³ÛŒØ± Ù¾Ø§ÛŒÙ‡ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    # destination_path: str = ""

class DebugRequest(BaseModel):
    product_name: str = Field(..., description="Ù†Ø§Ù… Ø¯Ù‚ÛŒÙ‚ ÙØ§Ø±Ø³ÛŒ Ù…Ø­ØµÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ.")

class DebugResponse(BaseModel):
    product_name: str
    embedding: List[float]


# --- 5. Ø³Ø§Ø®Øª Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† FastAPI ---
app = FastAPI(
    title="Headless Vector Search API (Debug & Production Ready)",
    description="Provides endpoints for pure vector search, hybrid search, and debugging.",
    version=API_VERSION
)

# --- 6. ØªÙˆØ§Ø¨Ø¹ Ù‡Ù…Ø²Ù…Ø§Ù† (Sync) ---
def initialize_database_sync():
    """ÙÙ‚Ø· Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    global collection, app_initialized
    if not os.path.isdir(DB_PATH):
        raise FileNotFoundError("Database path does not exist. Please download the database folder first.")
    
    logger.info(f"--- Ø¯Ø± Ø­Ø§Ù„ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ChromaDB Ø¯Ø± Ù…Ø³ÛŒØ±: {DB_PATH} ---")
    db_client = chromadb.PersistentClient(path=DB_PATH)
    collection = db_client.get_or_create_collection(name=COLLECTION_NAME)
    logger.info(f"âœ… Ø§ØªØµØ§Ù„ Ø¨Ù‡ ChromaDB Ù…ÙˆÙÙ‚ÛŒØªâ€ŒØ¢Ù…ÛŒØ² Ø¨ÙˆØ¯. Ú©Ø§Ù„Ú©Ø´Ù† '{COLLECTION_NAME}' Ø´Ø§Ù…Ù„ {collection.count()} Ø¢ÛŒØªÙ… Ø§Ø³Øª.")
    app_initialized = True


def search_sync_pure_vector(embedding: List[float]) -> List[SearchResult]:
    """
    Ø¬Ø³ØªØ¬ÙˆÛŒ ÙˆÚ©ØªÙˆØ±ÛŒ Ø®Ø§Ù„Øµ Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ùˆ ÙÛŒÙ„ØªØ± Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯.
    """
    logger.info("Performing PURE vector search (keyword filter disabled).")
    vector_search_results = collection.query(
        query_embeddings=[embedding],
        n_results=TOP_K_RESULTS,
    )

    if not vector_search_results or not vector_search_results.get('ids')[0]:
        logger.warning("No results found from pure vector search.")
        return []

    final_results = []
    ids, distances, documents = vector_search_results['ids'][0], vector_search_results['distances'][0], vector_search_results['documents'][0]
    for i in range(len(ids)):
        score = (1 - distances[i]) * 100
        final_results.append({"id": ids[i], "name": documents[i] if documents else "N/A", "score": score})
    return final_results


def search_sync_hybrid(embedding: List[float], keywords: List[str]) -> List[SearchResult]:
    """Ø¬Ø³ØªØ¬ÙˆÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙˆÚ©ØªÙˆØ± Ø¢Ù…Ø§Ø¯Ù‡."""
    logger.info("Performing HYBRID search (keywords first).")
    where_filter = {"$or": [{"$contains": kw} for kw in keywords]} if len(keywords) > 1 else {"$contains": keywords[0]}
    
    results_keyword = collection.get(where_document=where_filter, include=["documents"])
    
    if not results_keyword or not results_keyword.get('ids'):
        logger.warning("No results found after keyword filtering stage.")
        return []
        
    logger.info(f"Found {len(results_keyword['ids'])} results after keyword filter. Reranking...")
    vector_search_results = collection.query(
        query_embeddings=[embedding],
        n_results=TOP_K_RESULTS,
        where={"id": {"$in": results_keyword['ids']}}
    )

    if not vector_search_results or not vector_search_results.get('ids')[0]:
        logger.warning("No results found after reranking stage.")
        return []

    final_results = []
    ids, distances, documents = vector_search_results['ids'][0], vector_search_results['distances'][0], vector_search_results['documents'][0]
    for i in range(len(ids)):
        score = (1 - distances[i]) * 100
        final_results.append({"id": ids[i], "name": documents[i], "score": score})
    return final_results


def get_embedding_by_name_sync(product_name: str) -> Optional[List[float]]:
    """
    ÙˆÚ©ØªÙˆØ± Ø§Ù…Ø¨Ø¯ÛŒÙ†Ú¯ ÛŒÚ© Ù…Ø­ØµÙˆÙ„ Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ø§Ù… Ø¯Ù‚ÛŒÙ‚ Ø¢Ù† Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    logger.info(f"Debugging: Attempting to retrieve product by name: '{product_name}'")
    result = collection.get(
        where_document={"$eq": product_name},
        include=["embeddings"]
    )
    if result and result.get('embeddings'):
        logger.info(f"âœ… Debug: Product '{product_name}' found.")
        return result['embeddings'][0]
    else:
        logger.warning(f"âš ï¸ Debug: Product '{product_name}' NOT found.")
        return None


# ### ØªØºÛŒÛŒØ± Û±: ØªØ§Ø¨Ø¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² ÙÙˆÙ„Ø¯Ø± Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø´Ø¯ ###
def start_folder_download(url: str, output_path: str):
    """ØªØ§Ø¨Ø¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙÙˆÙ„Ø¯Ø± Ú©Ù‡ Ø¯Ø± Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯."""
    logger.info(f"ğŸš€ Ø´Ø±ÙˆØ¹ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙÙˆÙ„Ø¯Ø± Ø§Ø² {url} Ø¨Ù‡ Ù…Ø³ÛŒØ± {output_path}")
    try:
        # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ù¾Ø§ÛŒÙ‡
        Path(output_path).mkdir(parents=True, exist_ok=True)
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² gdown.download_folder Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù„ ÙÙˆÙ„Ø¯Ø±
        gdown.download_folder(url=url, output=output_path, quiet=False, use_cookies=False)
        logger.info(f"âœ… Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙÙˆÙ„Ø¯Ø± Ø¯Ø± Ù…Ø³ÛŒØ± {output_path} Ú©Ø§Ù…Ù„ Ø´Ø¯.")
        # Ù¾Ø³ Ø§Ø² Ø¯Ø§Ù†Ù„ÙˆØ¯ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒÙ… Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø±Ø§ Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ú©Ù†ÛŒÙ…
        # Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø§Ø®ØªÛŒØ§Ø±ÛŒ Ø§Ø³Øª
        logger.info("ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù¾Ø³ Ø§Ø² Ø¯Ø§Ù†Ù„ÙˆØ¯...")
        initialize_database_sync()
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙÙˆÙ„Ø¯Ø± {url}. Ø¯Ù„ÛŒÙ„: {e}", exc_info=True)


# --- 7. Endpoint Ù‡Ø§ÛŒ API (Asynchronous) ---
@app.post("/startup/")
async def startup_server():
    """Endpoint Ø¨Ø±Ø§ÛŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³."""
    global app_initialized
    if app_initialized:
        return {"status": "warning", "message": "Application is already initialized."}
    try:
        await asyncio.get_running_loop().run_in_executor(None, initialize_database_sync)
        return {"status": "success", "message": "Database initialized successfully."}
    except Exception as e:
        app_initialized = False
        logger.critical(f"âŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Failed to initialize database: {str(e)}")


# ### ØªØºÛŒÛŒØ± Û²: Endpoint Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø± Ø¨Ø§ ÙÙˆÙ„Ø¯Ø± Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯ ###
@app.post("/download-database/")
async def schedule_folder_download(request: DownloadRequest, background_tasks: BackgroundTasks):
    """Endpoint Ø¨Ø±Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù„ ÙÙˆÙ„Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³."""
    # Ù…Ø³ÛŒØ± Ù…Ù‚ØµØ¯ Ø«Ø§Ø¨Øª Ùˆ Ø¨Ø±Ø§Ø¨Ø± Ø¨Ø§ DB_PATH Ø§Ø³Øª
    background_tasks.add_task(start_folder_download, request.drive_link, DB_PATH)
    return {
        "status": "success",
        "message": "ÙˆØ¸ÛŒÙÙ‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙÙˆÙ„Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯.",
        "details": {"drive_link": request.drive_link, "save_location": DB_PATH}
    }


@app.post("/vector-search/", response_model=List[SearchResult], summary="Pure Vector Search (Debug)")
async def vector_search(request: VectorSearchRequest):
    """
    Endpoint Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ ÙˆÚ©ØªÙˆØ±ÛŒ Ø®Ø§Ù„Øµ (ÙÛŒÙ„ØªØ± Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯).
    """
    if not app_initialized:
        raise HTTPException(status_code=503, detail="Service is not initialized. Please call /startup first.")
    
    try:
        loop = asyncio.get_running_loop()
        final_results = await loop.run_in_executor(None, search_sync_pure_vector, request.embedding)
        logger.info(f"Returning {len(final_results)} pure vector search results.")
        return final_results
    except Exception as e:
        logger.error(f"Error during pure vector search: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="An error occurred during the search process.")


@app.post("/hybrid-search/", response_model=List[SearchResult], summary="Hybrid Search (Production)")
async def hybrid_search(request: VectorSearchRequest):
    """Endpoint Ø§ØµÙ„ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ (Ø§Ø¨ØªØ¯Ø§ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ØŒ Ø³Ù¾Ø³ ÙˆÚ©ØªÙˆØ±)."""
    if not app_initialized:
        raise HTTPException(status_code=503, detail="Service is not initialized. Please call /startup first.")
    if not request.keywords:
        raise HTTPException(status_code=400, detail="Keywords list cannot be empty.")
    try:
        normalized_keywords = [kw.lower() for kw in request.keywords]
        loop = asyncio.get_running_loop()
        final_results = await loop.run_in_executor(None, search_sync_hybrid, request.embedding, normalized_keywords)
        
        logger.info(f"Returning {len(final_results)} hybrid search results.")
        return final_results
    except Exception as e:
        logger.error(f"Error during hybrid search: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="An error occurred during the search process.")


@app.post("/get-embedding/", response_model=DebugResponse, summary="Debug: Get Embedding by Name")
async def get_embedding_by_name(request: DebugRequest):
    """
    ÛŒÚ© endpoint Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ú©Ù‡ ÙˆÚ©ØªÙˆØ± Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù…Ø­ØµÙˆÙ„ Ø±Ø§ Ø¨Ø§ Ù†Ø§Ù… Ø¯Ù‚ÛŒÙ‚ Ø¢Ù† Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
    """
    if not app_initialized:
        raise HTTPException(status_code=503, detail="Service is not initialized. Please call /startup first.")
    try:
        loop = asyncio.get_running_loop()
        embedding = await loop.run_in_executor(None, get_embedding_by_name_sync, request.product_name)
        if embedding:
            return {"product_name": request.product_name, "embedding": embedding}
        else:
            raise HTTPException(status_code=404, detail=f"Product '{request.product_name}' not found in the database.")
    except Exception as e:
        logger.error(f"Error during debug lookup: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="An error occurred during the debug lookup.")



@app.get("/", summary="Health Check")
async def read_root():
    """Endpoint Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª Ø³Ø±ÙˆÛŒØ³."""
    return {
        "status": "OK" if app_initialized else "Pending Initialization",
        "message": "Server is running. Call /startup to initialize model and DB, or /download-database to get it first.",
        "version": API_VERSION,
        "initialized": app_initialized
    }
